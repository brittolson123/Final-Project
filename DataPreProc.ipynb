{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brittolson123/Final-Project/blob/master/DataPreProc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "YqAvWzmk_R-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m2lVXKITeAF",
        "outputId": "de5d514b-b9c1-4112-92ce-4601f2ba94f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Git "
      ],
      "metadata": {
        "id": "lpvUXWB7CUP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd drive/MyDrive/CS5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT7cV1UTCZsr",
        "outputId": "91fa7bd8-9914-4240-d066-07d49e5e9ca9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment and only do once\n",
        "#! git clone https://github.com/AareanaReza/CS598-DLH-Final-Project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmifOJXNCtgO",
        "outputId": "b423ee13-8807-4c91-9493-15182d9251b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CS598-DLH-Final-Project'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), 609 bytes | 17.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# always pull before working on code\n",
        "#! git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trC6VJnyDC6C",
        "outputId": "456be98d-c68e-4575-e5ed-252e62800c6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CS598-DLH-Final-Project/Colab-Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hcEDi8LLJX_",
        "outputId": "6bd47956-604d-4a8c-e219-86fe310d23a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS598-DLH-Final-Project/Colab-Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries"
      ],
      "metadata": {
        "id": "pGLPPQgE_O5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gzip\n",
        "import csv\n",
        "from itertools import islice\n",
        "\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import sys\n",
        "import os\n"
      ],
      "metadata": {
        "id": "CtL6i0l3_NFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path Variables"
      ],
      "metadata": {
        "id": "9XXDnvd5_gkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PREPROCESSING_PATH = '/content/drive/MyDrive/CS598-DLH-Final-Project/Data-Preprocessing/'\n",
        "NOTEEVENTS_CSV_GZ = DATA_PREPROCESSING_PATH + 'Original-Data/NOTEEVENTS.csv.gz'\n",
        "outpath = DATA_PREPROCESSING_PATH + 'Output-Data/'\n"
      ],
      "metadata": {
        "id": "EyQyZP-e7oFN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform File to .csv and Look at Data"
      ],
      "metadata": {
        "id": "16dyVILO_tP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gzip.open(NOTEEVENTS_CSV_GZ, 'rt', newline='') as csv_file:\n",
        "    csv_data = csv_file.read()\n",
        "    #with open('my_file.csv', 'wt') as out_file:\n",
        "         #out_file.write(csv_data)"
      ],
      "metadata": {
        "id": "CGPGAwSP7OKC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = csv.DictReader(csv_data)\n",
        "for row in islice(reader, 100):\n",
        "  print(row)"
      ],
      "metadata": {
        "id": "bqwImw_X82di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "S2S-30AYARvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def anonimization_remover(inputfile, outputfile):\n",
        "    \"\"\" Anonimization mark '[** **]' and its content are removed\"\"\"\n",
        "    processed_file = open(outputfile, 'w')\n",
        "    with open(inputfile) as fp:\n",
        "        while True:\n",
        "            line = fp.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            cleaned_line = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', '', line)\n",
        "            processed_file.write(cleaned_line)\n",
        "    processed_file.close()"
      ],
      "metadata": {
        "id": "A79igKOxA9-D"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anonimization_remover(csv_data, outpath+'out_noanonim.csv')"
      ],
      "metadata": {
        "id": "vfcptbE8BWIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dico for references\n",
        "ones = {\"1\": \"one\", \"2\": \"two\", \"3\": \"three\", \"4\": \"four\", \"5\": \"five\",\n",
        "        \"6\": \"six\", \"7\": \"seven\", \"8\": \"eight\", \"9\": \"nine\"}\n",
        "afterones = {\"10\": \"ten\", \"11\": \"eleven\", \"12\": \"twelve\", \"13\": \"thirteen\", \"14\": \"fourteen\", \"15\": \"fifteen\",\n",
        "             \"16\": \"sixteen\", \"17\": \"seventeen\", \"18\": \"eighteen\", \"19\": \"nineteen\"}\n",
        "tens = {\"2\": \"twenty\", \"3\": \"thirty\", \"4\": \"fourty\", \"5\": \"fifty\",\n",
        "        \"6\": \"sixty\", \"7\": \"seventy\", \"8\": \"eighty\", \"9\": \"ninety\"}\n",
        "grand = {0: \" billion \", 1: \" million \", 2: \" thousand \", 3: \"\"}\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def get_next_line_without_moving(f):\n",
        "    pos = f.tell()\n",
        "    line = f.readline()\n",
        "    line = f.readline()\n",
        "    f.seek(pos)\n",
        "    return line\n",
        "\n",
        "\n",
        "def get_vocabulary(inputfile):\n",
        "    \"\"\" This procedure takes a MIMIC NoteEvents file and returns a dictionary\n",
        "    which contains words and their corresponding count \"\"\"\n",
        "    # Ignore first line (columns title)\n",
        "    # If comma in the line, ignore it as it is NOT text\n",
        "    # Otherwise, take the line, and foreach word in line, if word in dict.keys(), count++, otherwise new words\n",
        "    word_dict = dict()\n",
        "    with open(inputfile) as fp:\n",
        "        # Ignore first line\n",
        "        line = fp.readline()\n",
        "        while True:\n",
        "            line = fp.readline()\n",
        "            if line == \"\\n\" or \",\" in line or \"\\\"\" in line:\n",
        "                continue\n",
        "            if not line:\n",
        "                break\n",
        "            word_list = word_tokenize(line)\n",
        "            for w in word_list :\n",
        "                if w in word_dict.keys():\n",
        "                    word_dict[w] += 1\n",
        "                else:\n",
        "                    word_dict[w] = 1\n",
        "    print(\"Vocabulary size:\", len(word_dict))\n",
        "    return word_dict\n",
        "\n",
        "\n",
        "def show_histogram(distribution, n_bins, title):\n",
        "    plt.style.use('ggplot')\n",
        "    plt.title(title)\n",
        "    plt.hist(distribution, bins=n_bins)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_paragraph_distribution(inputfile):\n",
        "    \"\"\" Displays the number of paragraph in the file for each size of character\"\"\"\n",
        "    # Array saving the length of paragraphs\n",
        "    par_lengths = []\n",
        "    with open(inputfile) as fp:\n",
        "        while True:\n",
        "            line = fp.readline()\n",
        "            if line == \"\\n\":\n",
        "                continue\n",
        "            if not line:\n",
        "                break\n",
        "            par_lengths.append(len(line))\n",
        "    # Now we display the histograms\n",
        "    show_histogram(par_lengths, max(par_lengths), 'Number of paragraph with respect to its size')\n",
        "\n",
        "\n",
        "def replace_breakline_by_space(given_line, next_line):\n",
        "    \"\"\" Replaces '\\n' by ' ' at the end of the given line if exists\n",
        "    This function is called by paragraphFinder\n",
        "    \"\"\"\n",
        "    if len(given_line) == 0:\n",
        "        return given_line\n",
        "    if given_line.count('\"') > 0 :\n",
        "        return given_line\n",
        "    if next_line.count('\"') > 0 :\n",
        "        return given_line\n",
        "    if given_line[len(given_line)-1] != '\\n':\n",
        "        return given_line\n",
        "    given_line = given_line.replace(given_line[len(given_line)-1], ' ')\n",
        "    return given_line\n",
        "\n",
        "\n",
        "def three_dig_to_words(val):\n",
        "    \"\"\" Function converting number to words of 3 digit\n",
        "    Code from Barath Kumar\n",
        "    Link : https://stackoverflow.com/questions/15598083/python-convert-numbers-to-words\n",
        "    \"\"\"\n",
        "    if val != \"000\":\n",
        "        ans = \"\"\n",
        "        if val[0] in ones:\n",
        "            ans = ans + ones[val[0]] + \" hundred \"\n",
        "        if val[1:] in afterones:\n",
        "            ans = ans + afterones[val[1:]] + \" \"\n",
        "        elif val[1] in tens:\n",
        "            ans = ans + tens[val[1]] + \" \"\n",
        "        if val[2] in ones and val[1:] not in afterones:\n",
        "            ans = ans + ones[val[2]]\n",
        "        return ans\n",
        "\n",
        "\n",
        "def num_to_words(value):\n",
        "    \"\"\" This function takes an integer as an input, and outputs its text version\n",
        "    Works with integer from 0 to 999 999 999 999.\n",
        "    \"\"\"\n",
        "    # Padding with zeros\n",
        "    pad = 12 - len(str(value))\n",
        "    padded = \"0\" * pad + str(value)\n",
        "\n",
        "    # Exception case\n",
        "    if padded == \"000000000000\":\n",
        "        return \"zero\"\n",
        "\n",
        "    # Preparing the values before computation\n",
        "    result = \"\"\n",
        "    number_groups = [padded[0:3], padded[3:6], padded[6:9], padded[9:12]]\n",
        "\n",
        "    for key, val in enumerate(number_groups):\n",
        "        if val != \"000\":\n",
        "            result = result + three_dig_to_words(val) + grand[key]\n",
        "\n",
        "    result = re.sub(r'(^ *| *$)', ' ', result)\n",
        "    return result"
      ],
      "metadata": {
        "id": "xuJyDnnq-oei"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}